Field,Type,Allowed/Format,Source,Populate From / Rules,Required,Notes
source,string,,Passthrough,From normalization: platform of origin,TRUE,
source_id,string,,Passthrough,From normalization: unique post/record ID from platform,TRUE,
url,string,,Passthrough,From normalization: canonical URL to the record,TRUE,
permalink,string|null,,Passthrough,From normalization: platform-specific permalink path,FALSE,
title,string|null,,Passthrough,From normalization: title if available (posts only),FALSE,
text,string,,Passthrough,From normalization: main text content,TRUE,
parent_source,string|null,,Passthrough,"From normalization: hierarchical source category (e.g., ""social"")",FALSE,
subsource,string|null,,Passthrough,"From normalization: sub-channel identifier (e.g., subreddit, FB page, TikTok hashtag)",FALSE,
author.id,string,,Passthrough,From normalization: platform-specific author ID,TRUE,
author.name,string,,Passthrough,From normalization: display name or full name,TRUE,
author.handle,string,,Passthrough,From normalization: handle or username,TRUE,
author.gender,string|null,,Passthrough,From normalization: gender if available (YouScan approximates for IG/FB/TikTok),FALSE,
author.age,integer|null,,Passthrough,From normalization: age if available (YouScan approximates for IG/FB/TikTok),FALSE,
author.subscribers,integer|null,,Passthrough,From normalization: follower/subscriber count if available,FALSE,
country,string|null,,Passthrough,From normalization: ISO 3166-1 alpha-2 country code,FALSE,
published_at,datetime,,Passthrough,From normalization: creation time in UTC (ISO8601),TRUE,
language,string,,Passthrough,From normalization: ISO 639-1 language code,TRUE,
metrics.likes,integer,,Passthrough,From normalization: like/upvote/favorite count,TRUE,
metrics.comments,integer,,Passthrough,From normalization: comment/reply count,TRUE,
metrics.shares,integer|null,,Passthrough,From normalization: share/repost/retweet count,FALSE,
sentiment_raw,string|null,,Passthrough,"From normalization: source-provided sentiment if available (e.g., from YouScan export)",FALSE,
topics,array,string[]; max 30,Derived,Dictionary match: Category=topics,TRUE,From dictionary match against normalization text
symptoms,array,string[]; max 20,Derived,Dictionary match: Category=symptoms,TRUE,From dictionary match against normalization text
treatments,array,string[]; max 20,Derived,"Dictionary match: Category=treatments (normalize brands to generics, generic names)",TRUE,From dictionary match against normalization text
conditions,array,string[]; max 20,Derived,Dictionary match: Category=conditions,TRUE,From dictionary match against normalization text
companies,array,string[]; max 20,Derived,Dictionary match: Category=companies,TRUE,From dictionary match against normalization text
engagement_score,number,0-100+,Derived,Formula: likes + (2 × comments) + (3 × shares),TRUE,Weighted engagement calculation prioritizing interaction depth
engagement_label,enum,low|med|high,Derived,"Threshold-based: high if score ≥20, med if 10-19, low if <10",TRUE,Bucketed engagement for dashboard filtering
key_phrases,array,string[]; max 40,Derived,"Extract 5-10 medically relevant phrases using 5-category strategy: 1) Symptom+Context (""feeling shaky after eating""), 2) Treatment+Outcome (""acarbose trial""), 3) Timing Patterns (""1-2 hours after eating""), 4) Diagnostic Terms (""continuous glucose monitor""), 5) Medical Conditions (""reactive hypoglycemia""). Canonicalized and deduplicated.",TRUE,Used for Topics & Narratives word cloud visualization
bariatric_context,enum,none|weak|strong,Derived,"Logic: strong if conditions array contains ""PBH"" OR conditions array contains ""late_dumping"" OR topics array contains ""bariatric_surgery"" OR subsource matches bariatric communities (r/gastricsleeve, r/wls, r/gastricbypass, r/bariatricsurgery); weak if text contains indirect references (""since my surgery"", ""post-op"", ""after my procedure"", ""my operation""); else none. IMPORTANT: Evaluate after all entity extraction is complete.",TRUE,"Used by relevance scoring and dashboard filtering. Note: PBH = Post-Bariatric Hypoglycemia"
relevance_label,enum,relevant|borderline|not_relevant,Derived,"v6 EXPANDED LOGIC with Treatment and Company Groups. PBH_TREATMENTS=[avexitide,acarbose,diazoxide,octreotide]. GLP1_TREATMENTS=[semaglutide,tirzepatide,dulaglutide,liraglutide,exenatide]. COMPETITORS=[Novo_Nordisk,Eli_Lilly]. RELEVANT if: (conditions contains PBH) OR (companies contains Amylyx - avexitide is their only pipeline drug) OR (companies contains ANY COMPETITORS AND (bariatric_context!=none OR conditions contains PBH/hypoglycemia)) OR (treatments contains ANY PBH_TREATMENTS) OR (bariatric_context=strong AND symptoms.length≥2) OR (bariatric_context=strong AND conditions contains hypoglycemia/reactive_hypoglycemia) OR (bariatric_context=strong AND treatments contains ANY GLP1_TREATMENTS). BORDERLINE if: (bariatric_context=strong WITHOUT PBH indicators - general bariatric surgery discussion) OR (bariatric_context=weak AND treatments contains PBH_TREATMENTS AND symptoms.length≥2) OR (bariatric_context=weak AND symptoms.length≥3). NOT_RELEVANT if: (bariatric_context=none AND no PBH_TREATMENTS AND no relevant company mentions) OR (conditions contains reactive_hypoglycemia AND bariatric_context=none - reactive hypo without bariatric surgery is not PBH) OR (off-topic medical content without bariatric context).",TRUE,"v6 expands relevance to capture bariatric content and company mentions. Key changes: (1) bariatric_context=strong alone → borderline (was not_relevant in v5), (2) All PBH treatments trigger relevant (not just avexitide), (3) Amylyx mention → relevant (avexitide is their only drug), (4) Competitors + bariatric/PBH context → relevant, (5) reactive_hypoglycemia without bariatric context → not_relevant."
relevance_confidence,number,0.0-1.0,Derived,Model confidence score for relevance_label classification,TRUE,Confidence score for QA and threshold-based filtering
relevance_reason,string,,Derived,"Short text rationale for QA (examples: ""PBH mentioned"", ""strong bariatric context with PBH treatment"", ""strong bariatric context without PBH indicators"")",TRUE,QA trace for transparency
audience_label,enum,patient|hcp|industry|media|unknown,Derived,"Dictionary anchor patterns: patient if matches audience_anchor Label=patient_anchor patterns (""i have"", ""my symptoms"", ""since my surgery""); hcp if matches audience_anchor Label=hcp_anchor patterns (""my patient"", ""in clinic"", ""we see patients""); industry if pharma/business language; media if news style; unknown if unclear. CRITICAL: Personal experience markers override professional role mentions.",TRUE,Audience classification for dashboard segmentation
audience_confidence,number,0.0-1.0,Derived,"Model confidence score for audience_label classification. Typical ranges: 0.8-1.0 for clear anchors, 0.3-0.5 for unknown",TRUE,Confidence score inferred by model
themes,array,enum[]; max 8,Derived,"Derived roll-up from enrichment tags: Symptoms (if symptoms.length>0), Treatments (if treatments.length>0), Conditions/Diagnosis (if conditions.length>0), Bariatric Surgery (if topics includes bariatric_surgery), Access & Coverage (if topics includes access_coverage), Diagnostics (if topics includes diagnostics_monitoring), Diet (if topics includes dietary_modification), Care Settings (if topics includes care_settings)",TRUE,Presence-based mapping for Trends card visualization; multi-label allowed
sentiment_label,enum,positive|neutral|negative|mixed,Derived,"Base classification with PBH-specific adjustments: multiple PBH symptoms + help-seeking → lean negative; treatment improvements → consider mixed; strong relief language → positive",TRUE,Enhanced sentiment analysis tuned for PBH context
sentiment_confidence,number,0.0-1.0,Derived,"Confidence ranges: 0.8-1.0 for clear emotional indicators; 0.6-0.7 for moderate indicators; 0.4-0.5 for subtle/unclear tone",TRUE,Confidence in sentiment classification
emotions,array,enum[]; max 8,Derived,"Multi-select from [anger,fear,sadness,joy,frustration,anxiety,hope,relief]. Extract only with clear textual evidence. Cue mapping: anxiety (scared/worried), frustration (nothing works), relief (finally/better), etc.",TRUE,Evidence-based emotion detection with specific linguistic cue mapping
intent,array,enum[]; max 3,Derived,"Multi-select from [seeking_advice,sharing_experience,giving_advice,news,venting]. Pattern recognition: question marks → seeking_advice; past tense narratives → sharing_experience; imperative language → giving_advice",TRUE,Intent classification using linguistic pattern recognition
flags,array,enum[]; max 5,Derived,"Multi-select from [possible_PBH_misattribution,crisis,adverse_event]. Logic: possible_PBH_misattribution if (bariatric_context=strong AND conditions includes hypoglycemia/reactive_hypoglycemia/late_dumping AND NOT PBH AND ≥2 PBH symptoms); crisis if self-harm language; adverse_event (avexitide-only) if ALL true: (1) treatments contains avexitide OR (companies contains Amylyx AND trial context present), (2) temporal/causal language connects avexitide/study drug to adverse event, (3) text describes actual adverse event - NOT hypothetical/hearsay.",TRUE,"Enhanced flag logic with FDA-aligned event-based adverse event detection for avexitide, PBH misattribution detection, and safety monitoring"
debug_matches,array,string[]; max 40,Derived,"ENTRY IDs from dictionary for all Labels extracted (e.g., conditions_PBH_008, treatments_avexitide_024). Use exact ENTRY IDs from PBH_SIGNAL_DICTIONARY_v6.csv",TRUE,QA tracking of dictionary matches using standardized Entry_IDs for transparency and debugging
